{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd0c569cd2e17f62341e0f08a54f9a867c3c0d3a6f67454072d7de41a8b5dff8343",
   "display_name": "Python 3.9.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the datasets and concat them into one.\n",
    "# download the above dataset from https://archive.ics.uci.edu/ml/machine-learning-databases/00380/\n",
    "\n",
    "data= pd.concat([pd.read_csv(\"C:\\data\\spam comments/Youtube01-Psy.csv\"),\n",
    "                    pd.read_csv(\"C:\\data\\spam comments/Youtube02-KatyPerry.csv\"),\n",
    "                    pd.read_csv(\"C:\\data\\spam comments/Youtube03-LMFAO.csv\"),\n",
    "                    pd.read_csv(\"C:\\data\\spam comments/Youtube04-Eminem.csv\"),\n",
    "                    pd.read_csv(\"C:\\data\\spam comments/Youtube05-Shakira.csv\")])\n",
    "                    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now our data has comments of 5 different youtube vids, now lets check the spam and not spam comments\n",
    "\n",
    "print(len(data[data[\"CLASS\"]==0])) # NOT SPAM\n",
    "print(len(data[data[\"CLASS\"]==1])) #SPAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuuffle the dataset and seperate comments(content) and CLASS(spam or not spam)(label)\n",
    "\n",
    "data_shuf = data.sample(frac=1)\n",
    "data_content = data_shuf[\"CONTENT\"]\n",
    "data_label = data_shuf[\"CLASS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are gonna use pipline feature to apply our countvector and randomforests at the same time\n",
    "# onna set up the pipeline in this cell\n",
    "# we are using randomforestclassifier to train our dataset as its most efficient in this case\n",
    "# we are also using countvectorizer whoose main function is to break down a senrence or a paragraph into mere words and performing      very basic processing like removing all the words with punctuation marks, converting all words to lower case etc.\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"bag of words\", CountVectorizer()),\n",
    "    (\"random forest\", RandomForestClassifier())\n",
    "    ])\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we are gonna add countvectorizer in our randomforest\n",
    "make_pipeline(CountVectorizer(), RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(data_content[:1500], data_label[:1500]) # this is our training data ( which is upto 1500th row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(data_content[1500:], data_label[1500:])  # this is our testing data (which is after the 1500th row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(input):\n",
    "    x=pipeline.predict([input]) # 1 means SPAM\n",
    "    if(x[0]==1):\n",
    "        print(\"this is spam\")\n",
    "    else:\n",
    "        print(\"this is not spam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "this is not spam\n"
     ]
    }
   ],
   "source": [
    "check(\"great video man, really good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "this is spam\n"
     ]
    }
   ],
   "source": [
    "check(\"go check out my instagram channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "this is spam\n"
     ]
    }
   ],
   "source": [
    "check(\"subscribe to my channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.predict([\"great video man, you are so good\"]) # 0 means NOT SPAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.predict([\"click on my video\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}